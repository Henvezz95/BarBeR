{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os, sys, json, cv2, random\n",
    "from glob import glob\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.config import get_cfg\n",
    "\n",
    "base_path = '.'\n",
    "\n",
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(\"my_dataset_train\", {}, f'{base_path}/annotations/COCO/train.json', f'{base_path}/dataset/images/')\n",
    "register_coco_instances(\"my_dataset_val\", {}, f'{base_path}/annotations/COCO/val.json', f'{base_path}/dataset/images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata = MetadataCatalog.get(\"my_dataset_train\")\n",
    "train_dataset_dicts = DatasetCatalog.get(\"my_dataset_train\")\n",
    "val_metadata = MetadataCatalog.get(\"my_dataset_val\")\n",
    "val_dataset_dicts = DatasetCatalog.get(\"my_dataset_val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples=len(train_dataset_dicts)\n",
    "num_val_samples=len(val_dataset_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_train_steps = num_train_samples//batch_size\n",
    "num_val_steps = num_val_samples//batch_size\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n",
    "\n",
    "cfg.OUTPUT_DIR = './Saved Models/Detectron2_models/'\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset_train\")\n",
    "cfg.DATASETS.VAL = (\"my_dataset_val\",)\n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\",)\n",
    "cfg.INPUT.MIN_SIZE = 640\n",
    "cfg.INPUT.MIN_SIZE_TRAIN = 640\n",
    "cfg.INPUT.MIN_SIZE_TEST = 640\n",
    "cfg.INPUT.MAX_SIZE = 640\n",
    "cfg.INPUT.MAX_SIZE_TRAIN = 640\n",
    "cfg.INPUT.MAX_SIZE_TEST = 640\n",
    "cfg.DATALOADER.NUM_WORKERS = 0\n",
    "cfg.SOLVER.IMS_PER_BATCH = batch_size\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.MAX_ITER = 300*num_train_steps   \n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512 \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 3 \n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "#trainer = DefaultTrainer(cfg)\n",
    "#trainer.resume_or_load(resume=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator,DatasetEvaluator\n",
    "from detectron2.engine.hooks import HookBase\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2.data import DatasetMapper\n",
    "from detectron2.data import build_detection_train_loader\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"detectron2\").setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        train_augmentations = [\n",
    "            T.ResizeShortestEdge(short_edge_length=[640,640], max_size=640),\n",
    "            T.RandomBrightness(0.4, 1.6),\n",
    "            T.RandomSaturation(0.3, 1.7),\n",
    "            T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n",
    "            T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "        ] \n",
    "        return build_detection_train_loader(cfg, mapper=DatasetMapper(cfg, is_train=True, augmentations=train_augmentations))\n",
    "    \n",
    "\n",
    "class EarlyStoppingHook(HookBase):\n",
    "    def __init__(self, trainer, num_train_steps, num_val_steps, max_iter):\n",
    "        self.trainer = trainer\n",
    "        self._period = num_train_steps\n",
    "        self.num_val_steps = num_val_steps\n",
    "        self._max_iter = max_iter\n",
    "        self.best_model = trainer.model\n",
    "        self.last_valloss = []\n",
    "        self._cfg = trainer.cfg.clone()\n",
    "        self._cfg.DATASETS.TRAIN = trainer.cfg.DATASETS.VAL\n",
    "        self._loader = iter(build_detection_train_loader(self._cfg))\n",
    "\n",
    "    def _do_eval(self):\n",
    "        #result = self.trainer.test(self.trainer.cfg, self.trainer.model)['bbox']['AP']\n",
    "        total_loss = 0\n",
    "        for _ in tqdm(range(self.num_val_steps)):\n",
    "            data = next(self._loader)\n",
    "            with torch.no_grad():\n",
    "                loss_dict = self.trainer.model(data)\n",
    "                total_loss += sum(loss_dict.values())\n",
    "        total_loss = total_loss/self.num_val_steps\n",
    "        total_loss = total_loss.cpu().detach().numpy()\n",
    "\n",
    "        if not np.isnan(total_loss):  \n",
    "            if self.last_valloss:\n",
    "                if total_loss > max(self.last_valloss):\n",
    "                    self.best_model = trainer.model \n",
    "                    print('New best model!')\n",
    "            if len(self.last_valloss)>=10:\n",
    "                if np.argmax(self.last_valloss)==0 and total_loss < self.last_valloss[0]:\n",
    "                    raise Exception(\"Stopping early\")\n",
    "                self.last_valloss[:9] = self.last_valloss[1:]  \n",
    "                self.last_valloss[-1] = total_loss\n",
    "            else:\n",
    "                self.last_valloss.append(total_loss)\n",
    "        print(self.last_valloss)\n",
    "        \n",
    "\n",
    "    def after_step(self):\n",
    "        next_iter = self.trainer.iter + 1\n",
    "        if next_iter % self._period == 0 or next_iter >= self._max_iter:\n",
    "            self._do_eval()\n",
    "\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.register_hooks([EarlyStoppingHook(trainer, num_train_steps=num_train_steps, num_val_steps=num_val_steps, max_iter=cfg.SOLVER.MAX_ITER)])\n",
    "trainer.resume_or_load(resume=False)\n",
    "device = torch.device('cuda:0')\n",
    "trainer.model.to(device)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator,DatasetEvaluator\n",
    "from detectron2.engine.hooks import HookBase\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2.data import DatasetMapper\n",
    "from detectron2.data import build_detection_train_loader\n",
    "\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"detectron2\").setLevel(logging.INFO)\n",
    "\n",
    "\n",
    "\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        train_augmentations = [\n",
    "            T.RandomBrightness(0.4, 1.6),\n",
    "            T.RandomSaturation(0.3, 1.7),\n",
    "            T.ResizeShortestEdge(short_edge_length=[640,640], max_size=640),\n",
    "            T.RandomFlip(prob=0.5, horizontal=True, vertical=False),\n",
    "            T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "        ] \n",
    "        return build_detection_train_loader(cfg, mapper=DatasetMapper(cfg, is_train=True, augmentations=train_augmentations))\n",
    "    \n",
    "\n",
    "class EarlyStoppingHook(HookBase):\n",
    "    def __init__(self, trainer, eval_period, max_iter):\n",
    "        self.trainer = trainer\n",
    "        self._period = eval_period\n",
    "        self._max_iter = max_iter\n",
    "        self.best_model = trainer.model\n",
    "        self.last_AP = []\n",
    "\n",
    "    def _do_eval(self):\n",
    "        result = self.trainer.test(self.trainer.cfg, self.trainer.model)['bbox']['AP']\n",
    "        if not np.isnan(result):  \n",
    "            if self.last_AP:\n",
    "                if result > max(self.last_AP):\n",
    "                    self.best_model = trainer.model \n",
    "            print('New best model!')\n",
    "            if len(self.last_AP)>=10:\n",
    "                if np.argmax(self.last_AP)==0 and result < self.last_AP[0]:\n",
    "                    raise Exception(\"Stopping early\")\n",
    "                self.last_AP[:9] = self.last_AP[1:]  \n",
    "                self.last_AP[-1] = result\n",
    "            else:\n",
    "                self.last_AP.append(result)\n",
    "            print(self.last_AP)\n",
    "        \n",
    "\n",
    "    def after_step(self):\n",
    "        next_iter = self.trainer.iter + 1\n",
    "        if next_iter % self._period == 0 or next_iter >= self._max_iter:\n",
    "            self._do_eval()\n",
    "\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.register_hooks([EarlyStoppingHook(trainer, eval_period=num_iter, max_iter=cfg.SOLVER.MAX_ITER)])\n",
    "trainer.resume_or_load(resume=False)\n",
    "device = torch.device('cuda:0')\n",
    "trainer.model.to(device)\n",
    "#trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.clip([-1,-2,1,2,3,4,5], 0,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('./src')\n",
    "from bounding_box import BoundingBox\n",
    "from evaluators import coco_evaluator, pascal_voc_evaluator\n",
    "from utils.enumerators import BBFormat, BBType, CoordinatesType\n",
    "from utils.enumerators import BBFormat, CoordinatesType,  MethodAveragePrecision\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "sys.path.append('./algorithms/') \n",
    "from detectron2_detector import Detectron2_detector\n",
    "\n",
    "fasterRCNN_detector = Detectron2_detector(\"./Saved Models/Detectron2_models/mode_test.pth\")\n",
    "longest_edge_resize = 640\n",
    "\n",
    "with open('./annotations/COCO/val.json') as json_file:\n",
    "    coco_annotations = json.load(json_file)\n",
    "\n",
    "with open('./annotations/COCO/datasets_info.json') as json_file:\n",
    "    datasets_info = json.load(json_file)\n",
    "\n",
    "VIA_datasets = {}\n",
    "for dataset_name in datasets_info['datasets']:\n",
    "    with open(datasets_info['datasets'][dataset_name]) as json_file:\n",
    "        data = json.load(json_file)['_via_img_metadata']\n",
    "        VIA_datasets[dataset_name] = {value['filename']:value for _, value in data.items()}\n",
    "\n",
    "\n",
    "ann_index = 0\n",
    "image_counter = 0\n",
    "detected_bbs = []\n",
    "groundtruth_bbs = []\n",
    "\n",
    "for image_annotation in tqdm(coco_annotations['images']):\n",
    "    id = image_annotation['id']\n",
    "    file_name = image_annotation['file_name']\n",
    "    true_boxes = []\n",
    "    true_classes = []\n",
    "    true_polygons = []\n",
    "    remove_this_image = False\n",
    "    while coco_annotations['annotations'][ann_index]['image_id'] == id:\n",
    "        true_boxes.append(np.array(coco_annotations['annotations'][ann_index]['bbox']))\n",
    "        true_classes.append(coco_annotations['annotations'][ann_index]['category_id']-1)\n",
    "        true_polygons.append(np.array(coco_annotations['annotations'][ann_index]['segmentation']).reshape(4,2))\n",
    "        \n",
    "        ann_index+=1\n",
    "        if ann_index >= len(coco_annotations['annotations']):\n",
    "            break\n",
    "\n",
    "    \n",
    "    img_path = datasets_info['images'][file_name]['path']\n",
    "    img = cv2.imread(img_path)\n",
    "    image_counter+=1\n",
    "    H,W,_ = img.shape\n",
    "    if W > H:\n",
    "        W_new = longest_edge_resize\n",
    "        H_new = int(np.round((H*W_new)/W))\n",
    "    else:\n",
    "        H_new = longest_edge_resize\n",
    "        W_new = int(np.round((W*H_new)/H))\n",
    "\n",
    "\n",
    "\n",
    "    for i in range(len(true_boxes)):\n",
    "        true_boxes[i][0::2] = np.int32(np.round(W_new*true_boxes[i][0::2]/W))\n",
    "        true_boxes[i][1::2] = np.int32(np.round(H_new*true_boxes[i][1::2]/H))\n",
    "        true_polygons[i][:,0] = np.int32(np.round(W_new*true_polygons[i][:,0]/W))\n",
    "        true_polygons[i][:,1] = np.int32(np.round(H_new*true_polygons[i][:,1]/H))\n",
    "\n",
    "    img = cv2.resize(img, (W_new, H_new), cv2.INTER_CUBIC)\n",
    "    dataset_name = datasets_info['images'][file_name]['dataset']\n",
    "    boxes, classes, confidences =fasterRCNN_detector.detect(img)\n",
    "    detected_bbs.extend([BoundingBox(file_name, 0 if classes[i] == '1D' else 1, boxes[i], img_size=(W_new, H_new), confidence=confidences[i], bb_type=BBType.DETECTED) for i in range(len(boxes))])\n",
    "    groundtruth_bbs.extend([BoundingBox(file_name, true_classes[i], true_boxes[i], img_size=(W_new, H_new), confidence=1, bb_type=BBType.GROUND_TRUTH) for i in range(len(true_boxes))])\n",
    "print(coco_evaluator.get_coco_summary(groundtruth_bbs, detected_bbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_evaluator.get_coco_summary(groundtruth_bbs, detected_bbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_id = 0\n",
    "result = coco_evaluator.get_coco_summary(list(filter(lambda x: x.get_class_id() == class_id, groundtruth_bbs)),\n",
    "                                list(filter(lambda x: x.get_class_id() == class_id, detected_bbs)))\n",
    "\n",
    "Ap0 = result['AP']\n",
    "class_id = 1\n",
    "result = coco_evaluator.get_coco_summary(list(filter(lambda x: x.get_class_id() == class_id, groundtruth_bbs)),\n",
    "                                list(filter(lambda x: x.get_class_id() == class_id, detected_bbs)))\n",
    "\n",
    "Ap1 = result['AP']\n",
    "print(Ap0, Ap1, (Ap0+Ap1)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = coco_evaluator.get_coco_metrics(groundtruth_bbs, detected_bbs)[0]['interpolated recall']\n",
    "y = coco_evaluator.get_coco_metrics(groundtruth_bbs, detected_bbs)[0]['interpolated precision']\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_evaluator.get_coco_summary(groundtruth_bbs, detected_bbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal_voc_evaluator.get_pascalvoc_metrics(groundtruth_bbs,\n",
    "                          detected_bbs,\n",
    "                          iou_threshold=0.5,\n",
    "                          method=MethodAveragePrecision.EVERY_POINT_INTERPOLATION,\n",
    "                          generate_table=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainer.model, \"./Saved Models/Detectron2_models/model_final.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"./Saved Models/Detectron2_models/model_final.pt\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cfg = get_cfg()\n",
    "cfg.MODEL.WEIGHTS = \"./Saved Models/Detectron2_models/model_final.pth\"\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  \n",
    "cfg.DATASETS.TEST = (\"my_dataset_val\")\n",
    "predictor = DefaultPredictor(cfg)\n",
    "model = build_model(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_paths = glob('./dataset/images/*.jpg')\n",
    "longest_edge_resize = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(img_paths[0])\n",
    "H,W,_ = img.shape\n",
    "if W > H:\n",
    "    W_new = longest_edge_resize\n",
    "    H_new = int(np.round((H*W_new)/W))\n",
    "else:\n",
    "    H_new = longest_edge_resize\n",
    "    W_new = int(np.round((W*H_new)/H))\n",
    "\n",
    "img = cv2.resize(img, (W_new, H_new), cv2.INTER_CUBIC)\n",
    "\n",
    "input = [{'image':torch.from_numpy(np.transpose(img, (2, 0, 1))), \n",
    "         'height':H_new, \n",
    "         'width':W_new}]\n",
    "\n",
    "result = model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dictionary = result[0]['instances'].get_fields()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dictionary['pred_boxes'].tensor.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dictionary['scores'].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dictionary['pred_classes'].cpu().detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "counter = 0\n",
    "predictor = DefaultPredictor(trainer)\n",
    "\n",
    "for d in val_dataset_dicts:   \n",
    "    if np.random.uniform(0,1) > 0.03:\n",
    "        continue \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1], metadata=val_metadata)\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    plt.figure(figsize = (14, 10))\n",
    "    plt.imshow(cv2.cvtColor(v.get_image()[::2, ::2, ::-1], cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    counter+=1\n",
    "    if counter> 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv2.imread(d[\"file_name\"])\n",
    "outputs = predictor(im)\n",
    "v = Visualizer(im[:, :, ::-1], metadata=val_metadata)\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "plt.figure(figsize = (14, 10))\n",
    "plt.imshow(cv2.cvtColor(v.get_image()[::2, ::2, ::-1], cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instances = outputs[\"instances\"]\n",
    "detected_class_indexes = instances.pred_classes\n",
    "prediction_boxes = instances.pred_boxes\n",
    "\n",
    "metadata = MetadataCatalog.get(cfg.DATASETS.TRAIN[0])\n",
    "#class_catalog = metadata.thing_classes\n",
    "\n",
    "#for idx, coordinates in enumerate(prediction_boxes):\n",
    "#    class_index = detected_class_indexes[idx]\n",
    "#    class_name = class_catalog[class_index]\n",
    "#    print(class_name, coordinates)\n",
    "\n",
    "print(prediction_boxes, detected_class_indexes, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
